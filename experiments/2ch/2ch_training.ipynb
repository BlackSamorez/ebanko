{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142f48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebf32039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e909b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"data/dialogues.jsonl\", lines=True)\n",
    "df[\"dialogue\"] = df[\"dialogue\"].apply(lambda x: x[:2])\n",
    "df[\"reply\"] = df[\"dialogue\"].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8de8f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_tokenizer = AutoTokenizer.from_pretrained(\"sismetanin/rubert-toxic-pikabu-2ch\")\n",
    "\n",
    "preprocess_model = AutoModelForSequenceClassification.from_pretrained(\"sismetanin/rubert-toxic-pikabu-2ch\")\n",
    "preprocess_model = preprocess_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ecff5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:42<00:00,  3.42it/s]\n"
     ]
    }
   ],
   "source": [
    "logits = []\n",
    "\n",
    "PREPROCESS_BATCH_SIZE = 64\n",
    "\n",
    "for batch in tqdm(np.array_split(df[\"reply\"].to_list(), (len(df[\"reply\"].to_list()) - 1) / PREPROCESS_BATCH_SIZE + 1)):\n",
    "    ids = preprocess_tokenizer(batch.tolist(), return_tensors=\"pt\", padding=True, truncation=True,  pad_to_multiple_of=8, max_length=512)[\"input_ids\"].cuda()\n",
    "    result = preprocess_model(ids)['logits'].cpu().tolist()\n",
    "    logits.extend(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec5e13f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"logits\"] = logits\n",
    "df[\"toxic\"] = df[\"logits\"].apply(lambda x: np.exp(x[1]) / (np.exp(x[0]) + np.exp(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e5f3a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    22492.000000\n",
       "mean         0.679015\n",
       "std          0.266693\n",
       "min          0.001684\n",
       "25%          0.490738\n",
       "50%          0.729009\n",
       "75%          0.928834\n",
       "max          0.996112\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"toxic\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8e4db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANTILE = 0.75\n",
    "df = df[df[\"toxic\"] > df[\"toxic\"].quantile(QUANTILE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0a3b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_json(\"filtered.json\", orient='records', lines=True)\n",
    "df = pd.read_json(\"filtered.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c01194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be118a3a149470192142e3b3eb2b173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Grossmend/rudialogpt3_medium_based_on_gpt2\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Grossmend/rudialogpt3_medium_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8973a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_param(text: str) -> str:\n",
    "    tokens_count = len(tokenizer.encode(text))\n",
    "    if tokens_count <= 15:\n",
    "        len_param = '1'\n",
    "    elif tokens_count <= 50:\n",
    "        len_param = '2'\n",
    "    elif tokens_count <= 256:\n",
    "        len_param = '3'\n",
    "    else:\n",
    "        len_param = '-'\n",
    "    return len_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ef51955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8dcf2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DvachDataset:\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        prefix = self.df.iloc[i][\"dialogue\"][1]\n",
    "        text = self.df.iloc[i][\"dialogue\"][0]\n",
    "        item = self.tokenizer(f\"|0|{get_length_param(prefix)}|\" + prefix + tokenizer.eos_token +  f\"|1|{get_length_param(text)}|\" + text, max_length=512, padding='max_length', truncation=True)\n",
    "        item[\"labels\"] = item[\"input_ids\"].copy()\n",
    "        return item\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee94da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, eval_df = train_test_split(df, test_size=0.2)\n",
    "train_dataset = DvachDataset(train_df, tokenizer)\n",
    "eval_dataset = DvachDataset(eval_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2439ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fd7bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorWithPadding(tokenizer, max_length=512, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86d2da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62ccb094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir = \"2ch_training\",\n",
    "    evaluation_strategy = \"steps\",\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    gradient_accumulation_steps = 4,\n",
    "    num_train_epochs = 2,\n",
    "    save_strategy = \"steps\",\n",
    "    save_steps = 100,\n",
    "    fp16 = True,\n",
    "    eval_steps = 50,\n",
    "    dataloader_num_workers = 4,\n",
    "    label_names = [\"input_ids\"]\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = eval_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8f8d121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-black_samorez/.conda/envs/megatron/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4498\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 562\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='562' max='562' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [562/562 15:34, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.817141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.772659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.746009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.725636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.712691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.706857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.698079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.687727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.828700</td>\n",
       "      <td>0.685030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.828700</td>\n",
       "      <td>0.682737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1125\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1125\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to 2ch_training/checkpoint-100\n",
      "Configuration saved in 2ch_training/checkpoint-100/config.json\n",
      "Model weights saved in 2ch_training/checkpoint-100/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1125\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1125\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to 2ch_training/checkpoint-200\n",
      "Configuration saved in 2ch_training/checkpoint-200/config.json\n",
      "Model weights saved in 2ch_training/checkpoint-200/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1125\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1125\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to 2ch_training/checkpoint-300\n",
      "Configuration saved in 2ch_training/checkpoint-300/config.json\n",
      "Model weights saved in 2ch_training/checkpoint-300/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1125\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1125\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to 2ch_training/checkpoint-400\n",
      "Configuration saved in 2ch_training/checkpoint-400/config.json\n",
      "Model weights saved in 2ch_training/checkpoint-400/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1125\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1125\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to 2ch_training/checkpoint-500\n",
      "Configuration saved in 2ch_training/checkpoint-500/config.json\n",
      "Model weights saved in 2ch_training/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1125\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=562, training_loss=0.8091112998880949, metrics={'train_runtime': 936.5442, 'train_samples_per_second': 9.606, 'train_steps_per_second': 0.6, 'total_flos': 8352734046584832.0, 'train_loss': 0.8091112998880949, 'epoch': 2.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b71776b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in 2ch_release/config.json\n",
      "Model weights saved in 2ch_release/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"2ch_release\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fa52efce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'>иронизирую над твоими заёбами и ожиданиями что я кого либо буду пиздить >нахуй ты мне сдался тогда вообще с вами блядь'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = \"нужно допинать витю, который почему-то 24/7 охуенно занят, хотя при этом ничего не делает, чтобы записать\"\n",
    "test_input = test_input + \" Что скажешь?\" + tokenizer.eos_token +  \"|1|2|\"\n",
    "\n",
    "input_ids = tokenizer([test_input], return_tensors=\"pt\").input_ids\n",
    "\n",
    "tokenizer.decode(model.generate(input_ids.cuda(),\n",
    "                                max_length=len(tokenizer([test_input], return_tensors=\"pt\").input_ids[0]) + 32,\n",
    "                                bad_words_ids=[[tokenizer.pad_token_id]],\n",
    "                                force_words_ids=[[11649], [11649]],\n",
    "                                temperature=1.,\n",
    "                                repetition_penalty=10.,\n",
    "                                do_sample=True).cpu()[:, input_ids.shape[-1]:][0], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d96393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-megatron]",
   "language": "python",
   "name": "conda-env-.conda-megatron-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
